# SLAM 알고리즘 설명

실외 환경에서도 강인하게 작동하는 SLAM 방법과 센서를 찾기 위해 다양한 실험을 진행했습니다. 

![Screen Shot 2022-08-24 at 12.23.45 PM.png](SLAM%20%E1%84%8B%E1%85%A1%E1%86%AF%E1%84%80%E1%85%A9%E1%84%85%E1%85%B5%E1%84%8C%E1%85%B3%E1%86%B7%20%E1%84%89%E1%85%A5%E1%86%AF%E1%84%86%E1%85%A7%E1%86%BC%20387384e4a12f409893cbe791838ca726/Screen_Shot_2022-08-24_at_12.23.45_PM.png)

![Depth Camera (Intel Realsense)](SLAM%20%E1%84%8B%E1%85%A1%E1%86%AF%E1%84%80%E1%85%A9%E1%84%85%E1%85%B5%E1%84%8C%E1%85%B3%E1%86%B7%20%E1%84%89%E1%85%A5%E1%86%AF%E1%84%86%E1%85%A7%E1%86%BC%20387384e4a12f409893cbe791838ca726/Screen_Shot_2022-08-24_at_10.41.17_AM.png)

Depth Camera (Intel Realsense)

![2D LiDAR (YDLiDAR X4)](SLAM%20%E1%84%8B%E1%85%A1%E1%86%AF%E1%84%80%E1%85%A9%E1%84%85%E1%85%B5%E1%84%8C%E1%85%B3%E1%86%B7%20%E1%84%89%E1%85%A5%E1%86%AF%E1%84%86%E1%85%A7%E1%86%BC%20387384e4a12f409893cbe791838ca726/Screenshot_2022-11-13_at_12.50.40_PM.png)

2D LiDAR (YDLiDAR X4)

결과적으로 Monocular Camera 를 사용한 ORB-SLAM2 알고리즘에 GPS 데이터를 삽입해 개선하기로 결정했습니다. 

### ORB-SLAM2

ORB- SLAM2 는 세 단계로 이루어집니다.

1. Camera Tracking
이 단계에서는 프레임에서 Map point 를 추출해 차량의 자세를 추정합니다. 앞뒤 프레임에서 추출된 Map point 를 비교하는 과정을 통해, 특정 장소를 대표하는 프레임인 KeyFrame 을 추출합니다.
2. LocalMapping
이 단계에서는 제작한 지도 (Local Map) 에 카메라의 자세를 최적화 시킵니다. 새로 추출된 KeyFrame 을 Local Map 에 추가함으로써 지도를 확장합니다.
3. Loop Closing
차량이 이미 방문했던 장소를 재방문하면, 시스템은 이를 감지하고 누적된 에러를 보정합니다. ORB-SLAM2 는 Covisibility Graph 를 이용하여 이 과정을 수행합니다.

## 알고리즘 개선 과정

### Tracking 단계

![Untitled](SLAM%20%E1%84%8B%E1%85%A1%E1%86%AF%E1%84%80%E1%85%A9%E1%84%85%E1%85%B5%E1%84%8C%E1%85%B3%E1%86%B7%20%E1%84%89%E1%85%A5%E1%86%AF%E1%84%86%E1%85%A7%E1%86%BC%20387384e4a12f409893cbe791838ca726/Untitled.png)

경사, 도로의 울퉁불퉁함, 진흙 때문에 Odometry 값만으로는 차량의 정확한 이동을 측정하기 어려울 때 GPS 데이터를 이용하였습니다. 

**차량이 일정 거리 이상을 이동했을 때**만 이후 과정이 진행되도록 하여 연산량을 줄였습니다. 

또한 GPS 값을 기준으로 candidate keyframe 값을 비교함으로써 의미없는 keyframe 이 생성되는 것을 방지했습니다. 

### Local Mapping 단계

![Screenshot 2022-11-13 at 1.06.14 PM.png](SLAM%20%E1%84%8B%E1%85%A1%E1%86%AF%E1%84%80%E1%85%A9%E1%84%85%E1%85%B5%E1%84%8C%E1%85%B3%E1%86%B7%20%E1%84%89%E1%85%A5%E1%86%AF%E1%84%86%E1%85%A7%E1%86%BC%20387384e4a12f409893cbe791838ca726/Screenshot_2022-11-13_at_1.06.14_PM.png)

이 단계에서는 Covisibility 그래프를 만들 때 가중치 계산에 GPS 를 추가함으로써 정확도를 높였습니다. 

### 알고리즘 개선 후

저희는 이 세 과정에 GPS 데이터를 추가함으로써, 다음과 같은 이점을 얻을 수 있었습니다.

1. **의미 없는 연산을 방지함으로써 알고리즘의 Time Complexity 감소**
실외 주행 특성상 차량에게 이동 명령을 내려도 의도한 만큼 차량이 움직이지 않는 경우가 잦습니다. (진흙으로 인해 바퀴가 헛도는 현상 등) 
따라서 GPS 데이터를 이용해 차량의 이동 거리를 계산하여 만약 이동 거리가 유의미하지 않다면 Tracking 과정을 수행하지 않도록 하였습니다. 
또한 무의미한 KeyFrame 은 오히려 전체 지도의 정확도를 떨어뜨리기 때문에, KeyFrame 후보군 (Candidate KeyFrame) 과 기존 KeyFrame 사이의 거리가 일정 거리 이하일 때는 Map 에 추가하지 않도록 개발하였습니다. 
이를 통해 지도의 정확성을 높이고 연산량을 줄였습니다.
2. **Covisibility Graph 제작 과정에서의 정확도 향상**
새로운 KeyFrame 이 추가될 때, 동일한 위치의 지도를 공유하는 다른 KeyFrame 들의 Covisibility Graph 가 업데이트됩니다. 
이 그래프를 이용하여 모든 KeyFrame 을 비교하지 않고도 시스템은 차량의 자세를 추정할 수 있습니다. 이 그래프를 만들 때, KeyFrame 들의 Correlation 을 추정하기 위해 화면의 특징점들이 이용됩니다. 
하지만 실외 환경에서는 (특히 숲 지형에서) 실내보다 특징점을 추출하기 어렵기 때문에, 이 과정에서 GPS 데이터를 추가하여 KeyFrame 간의 거리를 비교하는 방식으로 알고리즘을 개선했습니다.
3. **Relocalization 정확도 향상**
차량이 Tracking 과정을 정상적으로 실행하지 못 했다면, 이전의 데이터를 이용해서 현재 위치를 추정해야 합니다. 
이 과정에서 KeyFrame Database 는 BOW (Bag Of Words) 를 이용해서 현재 Frame 과 유사도가 높은 KeyFrame 을 찾습니다. 하지만 이 과정은 많은 컴퓨팅 파워를 소모하고, 시간이 오래 걸립니다. 또한 KeyFrame Database 만 이용하는 것은 신뢰도가 높지 않습니다. 따라서 이 과정에도 GPS 데이터를 추가했습니다. 먼저, 현재 위치에서 먼 곳에 있는 KeyFrame 은 연산에서 제외했습니다. 이렇게 추려진 candidate KeyFrame 중 현재 위치와 비슷한 GPS 데이터를 가지고 있는 KeyFrame 만 연산하여, 
시간 복잡도를 줄이고 결정의 신뢰도를 높였습니다.
